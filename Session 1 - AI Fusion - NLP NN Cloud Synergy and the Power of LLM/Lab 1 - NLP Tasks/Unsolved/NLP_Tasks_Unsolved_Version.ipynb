{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf59d85",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP) Tasks - Unsolved Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eed6f7",
   "metadata": {},
   "source": [
    "In this assignment, you'll use various NLP libraries to complete tasks such as tokenization, stop word filtering, lemmatization, and sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85a0afe",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec35f1",
   "metadata": {},
   "source": [
    "Load the text from the `sample.txt` file and complete the following exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c64144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure these are installed:\n",
    "%pip install nltk\n",
    "%pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "%pip install textblob\n",
    "%pip install deep-translator\n",
    "%pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936531cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preload the nltk data\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82f47c3",
   "metadata": {},
   "source": [
    "### Exercise 1: Create a Word List\n",
    "Create a list of words from the sentence provided in the `sample.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f7664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text from sample.txt\n",
    "with open('../Resources/smart_stories.txt', 'r') as file:\n",
    "    sentence = file.read()\n",
    "\n",
    "# Create a word list\n",
    "word_list = []\n",
    "# Your code here to create a word list from the sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee318f4",
   "metadata": {},
   "source": [
    "### Exercise 2: Tokenize the Word List\n",
    "Tokenize the word list using `nltk` and `spacy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "\n",
    "# Your code here to tokenize the word list\n",
    "# Install nltk and download necessary resources if not already done\n",
    "# nltk.download('punkt')\n",
    "\n",
    "tokens_nltk = []\n",
    "tokens_spacy = []\n",
    "\n",
    "# Tokenize the word list\n",
    "# word_list = <from previous exercise>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7954fd8e",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a Stemmer and a Lemmatizer\n",
    "Use NLTK's stemmer and Spacy's lemmatizer on the tokenized list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5c2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Spacy lemmatizer\n",
    "# Your code here to stem and lemmatize\n",
    "stemmed_words = []\n",
    "lemmatized_words = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84e6b43",
   "metadata": {},
   "source": [
    "### Exercise 4: Filter out Stop Words\n",
    "Remove stop words from the word list using NLTK or Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c3937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Your code here to filter out stop words\n",
    "stop_words = []\n",
    "\n",
    "filtered_words_nltk = []\n",
    "filtered_words_spacy = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fd1fe9",
   "metadata": {},
   "source": [
    "### Exercise 5: Identify the Parts of Speech\n",
    "Identify the parts of speech of the words using NLTK and Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a4c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here to identify parts of speech\n",
    "\n",
    "pos_nltk = []\n",
    "pos_spacy = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d30eda",
   "metadata": {},
   "source": [
    "### Exercise 6: Perform Sentiment Analysis\n",
    "Analyze the sentiment of the text from `sample.txt` using `TextBlob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c96c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Your code here to perform sentiment analysis\n",
    "\n",
    "# Your analysis code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cc140b",
   "metadata": {},
   "source": [
    "### Exercise 7: Translate a Phrase into a Different Language\n",
    "Translate the text from `sample.txt` into French using the `translate` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35fb87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translate import Translator\n",
    "\n",
    "# Your code here to translate the phrase\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f214fe",
   "metadata": {},
   "source": [
    "### Exercise 8: Use NER to Find Important Nouns\n",
    "Use Named Entity Recognition (NER) to find important nouns in the text using Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafaaf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here to use NER with Spacy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6c9f13",
   "metadata": {},
   "source": [
    "### Exercise 9: Create a WordCloud\n",
    "Create a word cloud from the text using the `WordCloud` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d07bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your code here to create a WordCloud from the text in sample.txt"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
