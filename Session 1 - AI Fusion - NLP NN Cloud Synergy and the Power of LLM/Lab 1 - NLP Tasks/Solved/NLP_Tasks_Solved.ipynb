{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666a6634",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP) Tasks - Solved Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61171323",
   "metadata": {},
   "source": [
    "In this assignment, you'll use various NLP libraries to complete tasks such as tokenization, stop word filtering, lemmatization, and sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187e1c42",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af73e0a",
   "metadata": {},
   "source": [
    "The text is loaded from the `sample.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80003ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure these are installed:\n",
    "%pip install nltk\n",
    "%pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "%pip install textblob\n",
    "%pip install deep-translator\n",
    "%pip install wordcloud\n",
    "%pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fad52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preload the nltk data\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701351b9",
   "metadata": {},
   "source": [
    "### Exercise 1: Create a Word List\n",
    "Create a list of words from the sentence provided in the `sample.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5826f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text from sample.txt\n",
    "with open('../Resources/smart_stories.txt', 'r') as file:\n",
    "    sentence = file.read()\n",
    "# trim the whitespace from the beginning and end of the sentence\n",
    "sentence = sentence.strip()\n",
    "# remove extraneous whitespace from within the sentence\n",
    "sentence = \" \".join(sentence.split())\n",
    "\n",
    "# Create a word list\n",
    "word_list = sentence.split()\n",
    "print(\"Word List:\", word_list)\n",
    "print(\"Word Count:\", len(word_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bba444e",
   "metadata": {},
   "source": [
    "### Exercise 2: Tokenize the Word List\n",
    "Tokenize the word list using `nltk` and `spacy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c343e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Tokenizing using nltk\n",
    "tokens_nltk = nltk.word_tokenize(sentence)\n",
    "print(\"NLTK Tokenization:\", tokens_nltk)\n",
    "\n",
    "# Tokenizing using spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(sentence)\n",
    "tokens_spacy = [token.text for token in doc]\n",
    "print(\"Spacy Tokenization:\", tokens_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e149418d",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a Stemmer and a Lemmatizer\n",
    "Use NLTK's stemmer and Spacy's lemmatizer on the tokenized list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "stemmed_words = [ps.stem(word) for word in tokens_nltk]\n",
    "print(\"Stemmed Words (NLTK):\", stemmed_words)\n",
    "\n",
    "# Using Spacy's lemmatizer\n",
    "lemmatized_words = [token.lemma_ for token in doc]\n",
    "print(\"Lemmatized Words (Spacy):\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfdb893",
   "metadata": {},
   "source": [
    "### Exercise 4: Filter out Stop Words\n",
    "Remove stop words from the word list using NLTK or Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eba9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_words_nltk = [word for word in tokens_nltk if word.lower() not in stop_words]\n",
    "print(\"Filtered Words (NLTK):\", filtered_words_nltk)\n",
    "\n",
    "# Using Spacy to filter out stop words\n",
    "filtered_words_spacy = [token.text for token in doc if not token.is_stop]\n",
    "print(\"Filtered Words (Spacy):\", filtered_words_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc0b9d",
   "metadata": {},
   "source": [
    "### Exercise 5: Identify the Parts of Speech\n",
    "Identify the parts of speech of the words using NLTK and Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c226abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part-of-Speech tagging using nltk\n",
    "pos_nltk = nltk.pos_tag(tokens_nltk)\n",
    "print(\"Parts of Speech (NLTK):\", pos_nltk)\n",
    "\n",
    "# Using Spacy\n",
    "pos_spacy = [(token.text, token.pos_) for token in doc]\n",
    "print(\"Parts of Speech (Spacy):\", pos_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46928496",
   "metadata": {},
   "source": [
    "### Exercise 6: Perform Sentiment Analysis\n",
    "Analyze the sentiment of the text from `sample.txt` using `TextBlob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27630f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(sentence)\n",
    "print(\"Sentiment Polarity:\", blob.sentiment.polarity)\n",
    "print(\"Sentiment Subjectivity:\", blob.sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc4616b",
   "metadata": {},
   "source": [
    "### Exercise 7: Translate a Phrase into a Different Language\n",
    "Translate the text from `sample.txt` into French using the `translate` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4771bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Create a GoogleTranslator object for French translation\n",
    "translator = GoogleTranslator(source='auto', target='fr')\n",
    "\n",
    "# Translate the first 200 characters of the sentence to French\n",
    "translation = translator.translate(sentence[0:200])\n",
    "\n",
    "# Print the English text and the translated text\n",
    "print(\"English Text:\", sentence[0:200])\n",
    "print(\"Translated to French:\", translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af62212c",
   "metadata": {},
   "source": [
    "### Exercise 8: Use NER to Find Important Nouns\n",
    "Use Named Entity Recognition (NER) to find important nouns in the text using Spacy or Flair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b55f04",
   "metadata": {},
   "source": [
    "```python\n",
    "import spacy\n",
    "import streamlit as st\n",
    "\n",
    "# Load the pre-trained model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the text\n",
    "text = \"Peter Jackson is the director of The Lord of the Rings movies. He was born in New Zealand. The movies were filmed in New Zealand. The Lord of the Rings movies are based on the books by J.R.R. Tolkien, a British author. The books were written in the 1950s. The movies were filmed in the 2000s.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract entities\n",
    "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "# Display the text and entities\n",
    "st.write(\"Text:\", text)\n",
    "st.write(\"Entities:\")\n",
    "for entity in entities:\n",
    "    st.write(f\"{entity[0]} ({entity[1]})\")\n",
    "\n",
    "# Run the Streamlit app\n",
    "# Save this script as app.py and run `streamlit run app.py` in the terminal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b1d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# Load the NER tagger\n",
    "tagger = SequenceTagger.load(\"ner\")\n",
    "\n",
    "# Process the text\n",
    "text = \"Peter Jackson is the director of The Lord of the Rings movies. He was born in New Zealand. The movies were filmed in New Zealand. The Lord of the Rings movies are based on the books by J.R.R. Tolkien, a British author. The books were written in the 1950s. The movies were filmed in the 2000s.\"\n",
    "flair_sentence = Sentence(text)\n",
    "tagger.predict(flair_sentence)\n",
    "\n",
    "# Extract entities\n",
    "for entity in flair_sentence.get_spans('ner'):\n",
    "    print(entity.text, entity.get_label('ner').value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b03be",
   "metadata": {},
   "source": [
    "### Exercise 9: Create a WordCloud\n",
    "Create a word cloud from the text using the `WordCloud` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f9542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a WordCloud from the text\n",
    "wordcloud = WordCloud(width=800, height=400).generate(sentence)\n",
    "\n",
    "# Display the generated WordCloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6095e183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
