{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf07e65",
   "metadata": {},
   "source": [
    "# Building a GAN to Generate Handwritten Digit Images - Solved Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4761973",
   "metadata": {},
   "source": [
    "In this assignment, you'll use TensorFlow to build a simple Generative Adversarial Network (GAN) that generates images of handwritten digits from the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f6a9b",
   "metadata": {},
   "source": [
    "## Steps Overview:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48db5e",
   "metadata": {},
   "source": [
    "\n",
    "1. Create a Generator model and a Discriminator model\n",
    "2. Create the loss functions\n",
    "3. Create the training step function\n",
    "4. Create a function to generate and save the images\n",
    "5. Create the main training function\n",
    "6. Load the sample MNIST dataset\n",
    "7. Run the training function for 50 Epochs\n",
    "8. Assemble an animated GIF showing the progressively better images.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92fce74",
   "metadata": {},
   "source": [
    "### Exercise 1: Create the Generator and Discriminator Models\n",
    "Use TensorFlow to create the generator and discriminator models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required libraries\n",
    "%pip install tensorflow\n",
    "%pip install imageio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a1d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Create the generator model\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    return model\n",
    "\n",
    "# Create the discriminator model\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the generator and discriminator models\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "# Print the model summaries\n",
    "generator.summary()\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f6b6d",
   "metadata": {},
   "source": [
    "### Exercise 2: Create the Loss Functions\n",
    "Create the loss functions for the generator and the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d704459",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ace770",
   "metadata": {},
   "source": [
    "### Exercise 3: Create the Training Step Function\n",
    "Define a function to perform one step of training the GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "328bd04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([batch_size, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506fc96c",
   "metadata": {},
   "source": [
    "### Exercise 4: Create a Function to Generate and Save Images\n",
    "Generate images from random noise and save them at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bbe6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f19286",
   "metadata": {},
   "source": [
    "### Exercise 5: Create the Main Training Function\n",
    "Define the function that runs the GAN training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b12fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "        # Produce images for the GIF as we go\n",
    "        generate_and_save_images(generator, epoch + 1, seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256eea96",
   "metadata": {},
   "source": [
    "### Exercise 6: Load the MNIST Dataset\n",
    "Load and preprocess the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "\n",
    "batch_size = 256\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(60000).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ce60a9",
   "metadata": {},
   "source": [
    "### Exercise 7: Run the Training Function for 50 Epochs\n",
    "Run the training loop for 50 epochs and observe the generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8299ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# Optimizers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# Run the training loop\n",
    "train(train_dataset, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb080a72",
   "metadata": {},
   "source": [
    "### Exercise 8: Assemble an Animated GIF\n",
    "Use the saved images to create an animated GIF showing the GAN's progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20edc7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "def create_gif():\n",
    "    with imageio.get_writer('gan_training.gif', mode='I') as writer:\n",
    "        filenames = glob.glob('image_at_epoch_*.png')\n",
    "        filenames = sorted(filenames)\n",
    "        for filename in filenames:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "    print(\"GIF saved as 'gan_training.gif'\")\n",
    "\n",
    "create_gif()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8433b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
