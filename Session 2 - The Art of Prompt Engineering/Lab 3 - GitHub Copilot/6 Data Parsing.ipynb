{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Complex Data\n",
    "Here we use Few Shot learning to get GitHub Copilot to parse some complex text data.\n",
    "\n",
    "Here's what I've got:\n",
    "\n",
    "|Model|Tokens|PPM|Price|\n",
    "|---|---|---|---|\n",
    "|GPT-4 Turbo - gpt-4-turbo-2024-04-09, input|389093477|18|7003.68|\n",
    "|GPT-4 Turbo - gpt-4-turbo-2024-04-09, output|860213452|25|21505.34|\n",
    "|GPT-4 Turbo - gpt-4-0125-preview, input|552946730|59|32623.86|\n",
    "|Embedding models - text-embedding-3-small|297687725|28|8335.26|\n",
    "\n",
    "Here's what I want:\n",
    "\n",
    "|Model|Version|Input Price|Output Price|Training Price|Other Price|\n",
    "|---|---|---|---|---|---|\n",
    "|GPT-4 Turbo|gpt-4-turbo-2024-04-09|7003.68|21505.34|32623.86|0|\n",
    "|Embedding models|text-embedding-3-small|0|0|0|8335.26|\n",
    "\n",
    "Paste the following into the Chat window. (Note, all the numbers have been randomly generated.)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I want the following data parsed. If the Model ends in input, output, or training, then put the price into the input, output, or training columns.\n",
    "Also, break up the model into two columns, after eliminating the word input, output, or training. The columns for model are based on the first gap with a dash in it.\n",
    "If there isn't the word input, output, or training, put the price in the other price column.\n",
    "Don't write code or a function. Just parse the data and output it as CSV.\n",
    "\n",
    "For example:\n",
    "Model                                           Tokens     PPM  Price \n",
    "GPT-4 Turbo - gpt-4-turbo-2024-04-09, input \t389093477\t18\t7003.68\n",
    "GPT-4 Turbo - gpt-4-turbo-2024-04-09, output \t860213452\t25\t21505.34\n",
    "GPT-4 Turbo - gpt-4-turbo-2024-04-09, training  437284739   13  33244.22\n",
    "GPT-4 Turbo - gpt-4-turbo-2024-04-09            2380482     43  24324.11\n",
    "Should become\n",
    "Model,Version,Input Price,Output Price,Training Price,Other Price\n",
    "\"GPT-4 Turbo\",\"gpt-4-turbo-2024-04-09\",7003.68,21505.34,33244.22,24324.11\n",
    "Try to parse these:\n",
    "\n",
    "Model\tTokens\tPPM\tPrice\n",
    "GPT-4 Turbo - gpt-4-turbo-2024-04-09, input \t389093477\t18\t7003.68\n",
    "GPT-4 Turbo - gpt-4-turbo-2024-04-09, output \t860213452\t25\t21505.34\n",
    "GPT-4 Turbo - gpt-4-0125-preview, input \t552946730\t59\t32623.86\n",
    "GPT-4 Turbo - gpt-4-0125-preview, output \t448552781\t41\t18390.66\n",
    "GPT-4 Turbo - gpt-4-1106-preview, input \t309155374\t33\t10202.13\n",
    "GPT-4 Turbo - gpt-4-1106-preview, output \t870009064\t26\t22620.24\n",
    "GPT-4 Turbo - gpt-4-1106-vision-preview, input \t180936847\t33\t5970.92\n",
    "GPT-4 Turbo - gpt-4-1106-vision-preview, output \t1356571\t58\t78.68\n",
    "GPT-4 - gpt-4, input \t871373753\t37\t32240.83\n",
    "GPT-4 - gpt-4, output \t981464017\t40\t39258.56\n",
    "GPT-4 - gpt-4-32k, input \t773250449\t45\t34796.27\n",
    "GPT-4 - gpt-4-32k, output \t943955879\t27\t25486.81\n",
    "GPT-3.5 Turbo - gpt-3.5-turbo-0125, input \t256010777\t41\t10496.44\n",
    "GPT-3.5 Turbo - gpt-3.5-turbo-0125, output \t589882103\t20\t11797.64\n",
    "GPT-3.5 Turbo - gpt-3.5-turbo-1106, input \t840322596\t43\t36133.87\n",
    "GPT-3.5 Turbo - gpt-3.5-turbo-1106, output \t528276362\t16\t8452.42\n",
    "GPT-3.5 Turbo - gpt-3.5-turbo-instruct, input \t891761997\t50\t44588.1\n",
    "GPT-3.5 Turbo - gpt-3.5-turbo-instruct, output \t477582486\t53\t25311.87\n",
    "GPT-3.5 Turbo - gpt-3.5-turbo-0301, input \t690953925\t30\t20728.62\n",
    "GPT-3.5 Turbo - gpt-3.5-turbo-0301, output \t760657755\t22\t16734.47\n",
    "GPT-3.5 Turbo - gpt-3.5-turbo-0613, input \t902103446\t60\t54126.21\n",
    "GPT-3.5 Turbo - gpt-3.5-turbo-0613, output \t745678365\t44\t32809.85\n",
    "GPT-3.5 Turbo - gpt-3.5-turbo-16k-0613, input \t735600886\t42\t30895.24\n",
    "GPT-3.5 Turbo - gpt-3.5-turbo-16k-0613, output \t500507124\t25\t12512.68\n",
    "Assistants API - code interpreter \t320689863\t46\t14751.73\n",
    "Fine-tuning models - gpt-4 training \t513034855\t56\t28729.95\n",
    "Fine-tuning models - gpt-4 usage, input \t139425006\t37\t5158.73\n",
    "Fine-tuning models - gpt-4 usage, output \t982441547\t8\t7859.53\n",
    "Fine-tuning models - gpt-3.5-turbo training \t305290517\t55\t16790.98\n",
    "Fine-tuning models - gpt-3.5-turbo usage, input \t331351148\t11\t3644.86\n",
    "Fine-tuning models - gpt-3.5-turbo usage, output \t945127814\t37\t34969.73\n",
    "Embedding models - text-embedding-3-small \t297687725\t28\t8335.26\n",
    "Embedding models - text-embedding-3-large \t522993140\t56\t29287.62\n",
    "Embedding models - ada v2 \t92454495\t54\t4992.54\n",
    "Base models - davinci-002 \t708423619\t56\t39671.72\n",
    "Image models - DALL-E 3, Standard, 1024x1024 \t439510116\t39\t17140.89\n",
    "Image models - DALL-E 3, Standard, 1024x1792, 1792x1024 \t690841487\t54\t37305.44\n",
    "Image models - DALL-E 3, HD, 1024x1024 \t375339918\t10\t3753.4\n",
    "Image models - DALL-E 3, HD, 1024x1792, 1792x1024 \t588218890\t23\t13529.03\n",
    "Image models - DALL-E 2, 1024x1024 \t624039980\t40\t24961.6\n",
    "Image models - DALL-E 2, 512x512 \t479830599\t6\t2878.98\n",
    "Image models - DALL-E 2, 256x256 \t589879892\t37\t21825.56\n",
    "Audio models - Whisper \t480962769\t36\t17314.66\n",
    "Audio models - TTS \t24860239\t27\t671.23"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
