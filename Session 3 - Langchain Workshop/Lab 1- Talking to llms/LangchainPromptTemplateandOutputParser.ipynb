{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1213fe03",
   "metadata": {},
   "source": [
    "# Prompt Templates & Output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e02182d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../')\n",
    "import init_creds as creds\n",
    " \n",
    "AZURE_OPENAI_API_KEY = creds.get_api_key()\n",
    "AZURE_OPENAI_ENDPOINT = creds.get_endpoint()\n",
    "print(AZURE_OPENAI_API_KEY)\n",
    "print(AZURE_OPENAI_ENDPOINT)\n",
    " \n",
    "if not AZURE_OPENAI_API_KEY:\n",
    "    raise ValueError(\"No AZURE_OPENAI_API_KEY set for Azure OpenAI API\")\n",
    "if not AZURE_OPENAI_ENDPOINT:\n",
    "    raise ValueError(\"No AZURE_OPENAI_ENDPOINT set for Azure OpenAI API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d33196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
    "os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"] = \"gpt-4o-mini\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"]=\"2024-07-01-preview\"\n",
    "\n",
    "print(f'AZURE_OPENAI_API_KEY={os.environ[\"AZURE_OPENAI_API_KEY\"]}')\n",
    "print(f'AZURE_OPENAI_ENDPOINT={os.environ[\"AZURE_OPENAI_ENDPOINT\"]}')\n",
    "print(f'AZURE_OPENAI_DEPLOYMENT_NAME={os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]}')\n",
    "print(f'AZURE_OPENAI_API_VERSION={os.environ[\"AZURE_OPENAI_API_VERSION\"]}'    )\n",
    "\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01b2a1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "system_template = \"\"\"\n",
    "User loves going for trips and have gone to many different places in {place} and plans to visit few more soon.\n",
    "Can you create a tweet with {word_count} words for above?\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{place}\")]\n",
    ")\n",
    "formatted_prompt = prompt_template.invoke({\"word_count\": \"25\", \"place\": \"diego garcia\"})\n",
    "\n",
    "model.invoke(formatted_prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a82ed5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     31\u001b[39m final_prompt = ChatPromptTemplate.from_messages(\n\u001b[32m     32\u001b[39m     [\n\u001b[32m     33\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mYou are a cheeky four-year-old who is smart and funny\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     ]\n\u001b[32m     37\u001b[39m )\n\u001b[32m     38\u001b[39m user_query=\u001b[33m\"\u001b[39m\u001b[33mWhat is a watch?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43mmodel\u001b[49m.invoke(final_prompt.format(user_query=user_query)).content\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n",
    "examples=[\n",
    "    {\n",
    "        \"query\":\"What is a headphone?\",\n",
    "        \"answer\":\"Its a device that helps to hear and have fun.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\":\"What is a planet?\",\n",
    "        \"answer\":\"It's a sphere that goes around sun and gets tired.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# This is a prompt template used to format each individual example.\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{query}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a cheeky four-year-old who is smart and funny\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{user_query}\"),\n",
    "    ]\n",
    ")\n",
    "user_query=\"What is a watch?\"\n",
    "model.invoke(final_prompt.format(user_query=user_query)).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "009773d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "output_parser=CommaSeparatedListOutputParser()\n",
    "format_instructions=output_parser.get_format_instructions()\n",
    "format_instructions\n",
    "\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Help answer user questions in\"+format_instructions),\n",
    "    HumanMessage(content=\"Give me examples of five birds\"),\n",
    "]\n",
    "model.invoke(messages).content\n",
    "output_parser.parse(model.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b98c50c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "response_schemas=[\n",
    "    ResponseSchema(name=\"Country\",description=\"Answer to user's query\"),\n",
    "    ResponseSchema(name=\"ShortName\",description=\"Short name of the country\")\n",
    "]\n",
    "output_parser=StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "formatjson_instructions=output_parser.get_format_instructions()\n",
    "messages = [\n",
    "    SystemMessage(content=\"Help user answer user questions in\"+formatjson_instructions),\n",
    "    HumanMessage(content=\"Oldest country in the world\"),\n",
    "]\n",
    "\n",
    "output_parser.parse(model.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf17bba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9139ccfd",
   "metadata": {},
   "source": [
    "## Python Type Annotations\n",
    "\n",
    "The `->` symbol in Python is used for function return type annotations, introduced in Python 3.5 (PEP 484).\n",
    "\n",
    "### Basic Syntax:\n",
    "```python\n",
    "def function_name(parameter: type) -> return_type:\n",
    "    # function body\n",
    "```\n",
    "\n",
    "### Examples:\n",
    "```python\n",
    "# Function that takes a string and returns a string\n",
    "def greeting(name: str) -> str:\n",
    "    return f\"Hello, {name}\"\n",
    "\n",
    "# Function that takes two integers and returns an integer\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "    \n",
    "# Function that returns nothing (None)\n",
    "def log_message(message: str) -> None:\n",
    "    print(f\"Log: {message}\")\n",
    "```\n",
    "\n",
    "Type annotations are optional in Python and don't affect runtime behavior. They're useful for:\n",
    "- Documentation\n",
    "- IDE autocompletion and error checking\n",
    "- Static type checking with tools like mypy\n",
    "- Better code readability\n",
    "\n",
    "In LangChain code, you'll often see type annotations used to specify return types from various functions and methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
