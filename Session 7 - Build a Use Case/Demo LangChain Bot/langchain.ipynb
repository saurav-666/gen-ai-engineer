{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A LangChain Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../')\n",
    "import init_creds as creds\n",
    " \n",
    "AZURE_OPENAI_KEY = creds.get_api_key()\n",
    "AZURE_OPENAI_ENDPOINT = creds.get_endpoint()\n",
    " \n",
    "if not AZURE_OPENAI_KEY:\n",
    "    raise ValueError(\"No AZURE_OPENAI_KEY set for Azure OpenAI API\")\n",
    "if not AZURE_OPENAI_ENDPOINT:\n",
    "    raise ValueError(\"No AZURE_OPENAI_ENDPOINT set for Azure OpenAI API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_version=\"2024-07-01-preview\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You talk like a pirate. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    language: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"Conversation00001\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=100000,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "# Async function for node:\n",
    "async def call_model(state: State, config: dict):\n",
    "    chain = prompt | trimmer | model | parser\n",
    "    response = await chain.ainvoke(state, config)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Define graph as before:\n",
    "workflow = StateGraph(state_schema=State)\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ah\n",
      "oy\n",
      " again\n",
      ",\n",
      " Bill\n",
      "!\n",
      " Ye\n",
      " be\n",
      " a\n",
      " persistent\n",
      " lad\n",
      ",\n",
      " I\n",
      " see\n",
      "!\n",
      " A\n",
      " button\n",
      " factory\n",
      ",\n",
      " ye\n",
      " say\n",
      "?\n",
      " What\n",
      " kinds\n",
      " o\n",
      "’\n",
      " buttons\n",
      " do\n",
      " ye\n",
      " make\n",
      "?\n",
      " Be\n",
      " they\n",
      " for\n",
      " shirts\n",
      ",\n",
      " trousers\n",
      ",\n",
      " or\n",
      " perhaps\n",
      " som\n",
      "eth\n",
      "in\n",
      "’\n",
      " more\n",
      " fancy\n",
      " like\n",
      " pirate\n",
      " coats\n",
      "?\n",
      " Speak\n",
      " up\n",
      ",\n",
      " mate\n",
      "y\n",
      "!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "async def test_chat(query):\n",
    "    message = HumanMessage(query)\n",
    "    input_messages = [message]\n",
    "    async for chunk, metadata in app.astream(input={\"messages\": input_messages}, config=config, stream_mode=\"messages\"):\n",
    "        if isinstance(chunk, AIMessage):\n",
    "            yield chunk.content\n",
    "\n",
    "async for content in test_chat(\"Hi there, my name is Bill, and I work in a button factory.\"):\n",
    "    print(content)\n",
    "\n",
    "# await test_chat(\"One Day\")\n",
    "# await test_chat(\"My boss comes up to me.\")\n",
    "# await test_chat(\"He says, Hey Bill, whatcha doin'?\")    \n",
    "# await test_chat(\"I said, nuthin'\")  \n",
    "# await test_chat(\"He said, Well then, do this! And he started moving his hands around in big circles.\")   \n",
    "# await test_chat(\"So I did.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataViz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
